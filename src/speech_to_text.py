"""
MÃ³dulo para transcriÃ§Ã£o de Ã¡udio usando Whisper (OpenAI).
"""

import whisper
from typing import Optional, Dict, Any


class SpeechToText:
    """Classe para conversÃ£o de Ã¡udio em texto usando Whisper."""
    
    def __init__(self, model_name: str = "small", language: str = "pt"):
        """
        Inicializa o modelo Whisper.
        
        Args:
            model_name: Nome do modelo ('tiny', 'base', 'small', 'medium', 'large')
            language: CÃ³digo do idioma (pt, en, es, fr, etc.)
        """
        self.language = language
        self.model_name = model_name
        
        print(f"ðŸ“¥ Carregando modelo Whisper '{model_name}'...")
        self.model = whisper.load_model(model_name)
        print(f"âœ… Modelo carregado com sucesso!")
    
    def transcribe(self, audio_file: str, language: Optional[str] = None) -> str:
        """
        Transcreve um arquivo de Ã¡udio.
        
        Args:
            audio_file: Caminho do arquivo de Ã¡udio
            language: Idioma opcional (usa o padrÃ£o se nÃ£o especificado)
            
        Returns:
            Texto transcrito
        """
        lang = language or self.language
        
        print(f"ðŸ§  Transcrevendo Ã¡udio (idioma: {lang})...")
        
        result = self.model.transcribe(
            audio_file,
            language=lang,
            fp16=False  # Compatibilidade com CPU
        )
        
        transcription = result["text"].strip()
        print(f"ðŸ“ TranscriÃ§Ã£o: {transcription}")
        
        return transcription
    
    def transcribe_detailed(self, audio_file: str, language: Optional[str] = None) -> Dict[str, Any]:
        """
        Transcreve com informaÃ§Ãµes detalhadas.
        
        Args:
            audio_file: Caminho do arquivo de Ã¡udio
            language: Idioma opcional
            
        Returns:
            DicionÃ¡rio com transcriÃ§Ã£o e metadados
        """
        lang = language or self.language
        
        print(f"ðŸ§  Transcrevendo Ã¡udio (modo detalhado)...")
        
        result = self.model.transcribe(
            audio_file,
            language=lang,
            fp16=False,
            verbose=False
        )
        
        return {
            "text": result["text"].strip(),
            "language": result.get("language", lang),
            "segments": result.get("segments", []),
        }


def transcribe_audio(audio_file: str, model: str = "small", language: str = "pt") -> str:
    """
    FunÃ§Ã£o auxiliar para transcriÃ§Ã£o rÃ¡pida.
    
    Args:
        audio_file: Arquivo de Ã¡udio
        model: Modelo Whisper
        language: Idioma
        
    Returns:
        Texto transcrito
    """
    stt = SpeechToText(model_name=model, language=language)
    return stt.transcribe(audio_file)


if __name__ == "__main__":
    # Teste do mÃ³dulo
    import sys
    
    if len(sys.argv) > 1:
        audio_path = sys.argv[1]
        text = transcribe_audio(audio_path)
        print(f"\nâœ… Resultado: {text}")
    else:
        print("Uso: python speech_to_text.py <caminho_do_audio>")
